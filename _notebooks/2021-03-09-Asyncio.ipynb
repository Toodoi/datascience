{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-03-09-Asyncio.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijRhcvBwC8aU"
      },
      "source": [
        "# \"Asynchronous I/O\"\r\n",
        "> \"Experimenting with the asyncio library to improve API and database storage performance\"\r\n",
        "\r\n",
        "- toc: false\r\n",
        "- branch: master\r\n",
        "- comments: true\r\n",
        "- categories: [project, ETL]\r\n",
        "- hide: false\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSWcyq2uZqCm"
      },
      "source": [
        "[Asyncio](https://docs.python.org/3/library/asyncio.html) is a python library which allows the execution of code concurrently through the use of coroutines. Coroutines are functions that can suspend their execution and pass control of the program to another coroutine while they wait for something to happen. This is powerful because it allows the program to continue executing lines of code elsewhere in the program while it waits for some event such as an API response to occur. \r\n",
        "\r\n",
        "In this example I am making 214 requests to the Alpaca API and downloading stock price data in 15 minute intervals for roughly two months for each request. I then use the data to insert over 210,000 records into a PostgreSQL database. Using synchronous code, this took 203.6 seconds to complete compared to 32.8 seconds using coroutines with the asyncio library. This marks a 520% improvement in performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSH9SfDqfCPQ"
      },
      "source": [
        "## Syntax and examples\r\n",
        "To declare a coroutine, the ```async``` keyword is used.\r\n",
        "\r\n",
        "To pass control to another coroutine, the ```await``` keyword is used.\r\n",
        "\r\n",
        "The ```asyncio.run()``` call creates an event loop and runs the coroutine inside it. The event loop is like a ```while True``` statement which is constantly running and checking in to see if coroutines have finished or received a response in the case of a network request.\r\n",
        "\r\n",
        "In the execution below, because the ```await``` keyword is used before the sleep argument, the program continues to run other lines while it waits for the sleep to finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUq-T8kbjYCH",
        "outputId": "fc950055-61ff-4fbc-c56b-64e145e5ee95"
      },
      "source": [
        "import asyncio\r\n",
        "import time\r\n",
        "\r\n",
        "async def main():\r\n",
        "  print(f\"Started at {time.strftime('%X')}\")\r\n",
        "  print('Hello')\r\n",
        "  await asyncio.sleep(1)\r\n",
        "  print('World')\r\n",
        "\r\n",
        "  print(f\"Finished at {time.strftime('%X')}\")\r\n",
        "\r\n",
        "asyncio.run(main())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started at 05:58:09\n",
            "Hello\n",
            "World\n",
            "Finished at 05:58:10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAQRqjFE_EQG"
      },
      "source": [
        "Here, the gather function is used to call the ```say_after``` function and runs it concurrently with two different inputs. Even though the print statement \"...World\" is sent first, it ends up being printed last because it has a larger delay parameter and the function is running concurrently with both inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAeEivgjfLd5",
        "outputId": "c592884d-00ef-44ee-fc79-2067eefbdf1d"
      },
      "source": [
        "async def say_after(delay, text):\r\n",
        "  await asyncio.sleep(delay)\r\n",
        "  print(text)\r\n",
        "\r\n",
        "async def main():\r\n",
        "  await asyncio.gather(\r\n",
        "    say_after(2, '...World'),\r\n",
        "    say_after(1, 'Hello...')\r\n",
        "  )\r\n",
        "\r\n",
        "asyncio.run(main())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello...\n",
            "...World\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfXMaEdaDhZq"
      },
      "source": [
        "## Async stock price dump\r\n",
        "Below is the script I used to asynchronously get my data and insert it into my database with a few explanatory comments. Along with asyncio, I needed aiohttp which is a http client/server for asyncio and asyncpg which is the psycopg2 equivalent when using asyncio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qUdm_APC8ig"
      },
      "source": [
        "import json\r\n",
        "import requests\r\n",
        "import datetime, time\r\n",
        "import aiohttp, asyncpg\r\n",
        "\r\n",
        "headers = {\r\n",
        "    \"APCA-API-KEY-ID\": config.API_KEY,\r\n",
        "    \"APCA-API-SECRET-KEY\": config.API_SECRET\r\n",
        "  }\r\n",
        "\r\n",
        "async def write_to_db(connection, params):\r\n",
        "    await connection.copy_records_to_table('stock_price', records=params)\r\n",
        "\r\n",
        "\r\n",
        "async def get_price(pool, stock_id, url):\r\n",
        "    try:\r\n",
        "        async with pool.acquire() as connection:\r\n",
        "            async with aiohttp.ClientSession(headers=headers) as session:\r\n",
        "                async with session.get(url=url) as response:\r\n",
        "                    resp = await response.read()\r\n",
        "                    response = json.loads(resp)\r\n",
        "                    for key in response.keys():\r\n",
        "                        # final list of data is created and dispatched to the database\r\n",
        "                        params = [(stock_id, datetime.datetime.fromtimestamp(bar['t'] / 1000.0), round(bar['o'], 2), round(bar['h'], 2), round(bar['l'], 2), round(bar['c'], 2), bar['v']) for bar in response[key]]\r\n",
        "                    await write_to_db(connection, params)\r\n",
        "\r\n",
        "    except Exception as e:\r\n",
        "        print(\"Unable to get url {} due to {}.\".format(url, e.__class__))\r\n",
        "\r\n",
        "\r\n",
        "async def get_prices(pool, symbol_urls):\r\n",
        "    try:\r\n",
        "        # schedule aiohttp requests to run concurrently for all stocks\r\n",
        "        # like above, gather is used to send many inputs to a coroutine and run then all concurrently\r\n",
        "        ret = await asyncio.gather(*[get_price(pool, stock_id, symbol_urls[stock_id]) for stock_id in symbol_urls])\r\n",
        "        print(\"Finalized all. Returned  list of {} outputs.\".format(len(ret)))\r\n",
        "    except Exception as e:\r\n",
        "        print(e)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "async def get_stocks():\r\n",
        "    # create database connection pool (this is a shared pool of database connections so that many inserts can happen concurrently)\r\n",
        "    pool = await asyncpg.create_pool(user=config.DB_USER, password=config.DB_PASS, database=config.DB_NAME,\r\n",
        "                                     host=config.DB_HOST, command_timeout=60)\r\n",
        "\r\n",
        "    # get a connection\r\n",
        "    async with pool.acquire() as connection:\r\n",
        "        stocks = await connection.fetch(\"SELECT * FROM stock WHERE id IN (SELECT holding_id FROM etf_holding)\")\r\n",
        "\r\n",
        "        symbol_urls = {}\r\n",
        "        for stock in stocks:\r\n",
        "          # create a dictionary of urls for the API calls\r\n",
        "            symbol_urls[stock[\r\n",
        "                'id']] = f'https://data.alpaca.markets/v1/bars/15Min?symbols={stock[\"symbol\"]}&limit=1000'\r\n",
        "\r\n",
        "\r\n",
        "    await get_prices(pool, symbol_urls)\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "asyncio.run(get_stocks())\r\n",
        "end = time.time()\r\n",
        "\r\n",
        "print(f'Took {end-start} seconds to run.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjx4nSXjEVgW"
      },
      "source": [
        "##Synchronous run time\r\n",
        "\r\n",
        "\r\n",
        "![picture](https://drive.google.com/uc?id=13v6MLeFAPlMQDoN8eNkFULu7pdsGffWm)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt2yb19DJ2S9"
      },
      "source": [
        "##Asynchronous run time\r\n",
        "\r\n",
        "![picture](https://drive.google.com/uc?id=1k3WnrHn2BbDqWnGeUXq0ceRSzcdBcsIb)"
      ]
    }
  ]
}
